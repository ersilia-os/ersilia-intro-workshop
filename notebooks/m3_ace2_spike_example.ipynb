{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ACE2-Spike protein interaction\n",
        "\n",
        "This notebook shows the steps to clean up a dataset obtained from a published study (Yang et al, Nature Microbilogy, 2023) and train a machine learning model based on that data.\n",
        "\n",
        "_This notebook is prepared to run locally when clonning this repository, if you want to run it in Colab please make sure to add the datasets on Colab and redirect the paths as needed_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  1. Data Cleaning\n",
        "\n",
        "We have downloaded two of the supplementary files, for Fig 2b (natural product screening) and Extended Data Figure 1b (synthetic drugs). We have kept the columns \"Drug Cas\", \"Drug Name\", \"Log2FoldChange\" and \"-Log10Pvalue\" in individual .csv files.\n",
        "We will start the cleaning process from those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "DATAPATH = \"../data/m3_datasets/ace2-spike\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = [\"natural\", \"synthetic\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ry7vfsFX_LEH"
      },
      "outputs": [],
      "source": [
        "#these files are separated by ; instead of , since the names of the drugs contain ,\n",
        "np = pd.read_csv(os.path.join(DATAPATH,\"original\",\"natural_products_screening.csv\"), sep=\";\", decimal=\",\") \n",
        "sp = pd.read_csv(os.path.join(DATAPATH,\"original\",\"synthetic_drugs_screening.csv\"), sep=\";\", decimal=\",\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we need a function to get the SMILES from the CAS number\n",
        "# Pubchem has both identifiers, so we can go there to obtain the smiles\n",
        "\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "\n",
        "def get_smiles_from_cas(cas_number):\n",
        "    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/{cas_number}/property/CanonicalSMILES/TXT\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        return response.text.strip()\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we will run a small loop to process both datasets\n",
        "for d in datasets:\n",
        "    df = pd.read_csv(os.path.join(DATAPATH, \"original\", \"{}_products_screening.csv\".format(d)), sep=\";\", decimal=\",\") \n",
        "    smiles = []\n",
        "    for i, cas in tqdm(enumerate(sp[\"drug CAS\"].tolist())):\n",
        "        smi = get_smiles_from_cas(cas)\n",
        "        smiles += [smi]\n",
        "    smiles_ = []\n",
        "    for smi in smiles:\n",
        "        if smi is None:\n",
        "            smiles_ += [None]\n",
        "        else:\n",
        "            smiles_ += [smi.split(\"\\n\")[0]]\n",
        "    df[\"SMILES\"] = smiles_\n",
        "    df.to_csv(os.path.join(DATAPATH, \"processed\", \"{}_products_screening_with_smiles.csv\".format(d)), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# next, we obtain the Canonical format of the SMILES\n",
        "# We use the standardiser package for that\n",
        "\n",
        "from rdkit import Chem\n",
        "from standardiser import standardise\n",
        "\n",
        "for d in datasets:\n",
        "    df = pd.read_csv(os.path.join(DATAPATH,\"processed\", \"{}_products_screening_with_smiles.csv\".format(d)), sep=\",\")\n",
        "    df = df[df[\"SMILES\"].notnull()]\n",
        "    std_smi = []\n",
        "    for smi in df[\"SMILES\"].tolist():\n",
        "        mol = Chem.MolFromSmiles(smi)\n",
        "        try:\n",
        "            mol = standardise.run(mol)\n",
        "            smi = Chem.MolToSmiles(mol)\n",
        "        except:\n",
        "            smi = None\n",
        "        std_smi += [smi]\n",
        "    data = {\n",
        "    \"CAS\": df[\"drug CAS\"].tolist(),\n",
        "    \"SMILES\": std_smi,\n",
        "    \"Log2FoldChange\": df[\"Log2FoldChange\"].tolist(),\n",
        "    \"mLogPvalue\": df[\"mLog10Pvalue\"].tolist()\n",
        "    }\n",
        "    data = pd.DataFrame(data)\n",
        "    data = data.sample(data.shape[0]) #shuffling of the data\n",
        "    data = data[data[\"SMILES\"].notnull()]\n",
        "    data.to_csv(os.path.join(DATAPATH, \"processed\", \"{}_products_ace2_spike_processed.csv\".format(d)), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Model Training\n",
        "\n",
        "We will use the lazyQSAR package to train a model. We will first analyse the datasets to understand the distribution of our activity of interest, and what might be a good cut-off for our problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
